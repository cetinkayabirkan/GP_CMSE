{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel\n",
    "\n",
    "RootDir = '/mnt/research/turbulence/ml/data/'\n",
    "fig, p = plt.subplots(2,3,figsize=(15,10),sharex=True)\n",
    "\n",
    "B0_all = []\n",
    "SolWeight_all = []\n",
    "ForcingAmp_all = []\n",
    "U_all = []\n",
    "T_all = []\n",
    "\n",
    "ke_all = []\n",
    "me_all = []\n",
    "sm_all = []\n",
    "am_all = []\n",
    "pb_all = []\n",
    "\n",
    "dynTime_all = []\n",
    "\n",
    "data_all = []\n",
    "\n",
    "for Dir in glob.glob(RootDir + '256_*'):\n",
    "    Dir_parts = Dir.split('_')\n",
    "    B0 = float(Dir_parts[-1])\n",
    "    SolenoidalWeight = float(Dir_parts[-2])\n",
    "    ForcingAmpl = float(Dir_parts[-3])\n",
    "    \n",
    "\n",
    "    \n",
    "    B0_all.append(B0)\n",
    "    SolWeight_all.append(SolenoidalWeight)\n",
    "    ForcingAmp_all.append(ForcingAmpl)\n",
    "    \n",
    "\n",
    "    try:\n",
    "        data = np.genfromtxt(Dir + '/id0/Turb.hst')\n",
    "        data_all.append(data)\n",
    "    except:\n",
    "        print('check ', Dir)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # Estimating the rms velocity U based on the forcing amplitude.\n",
    "    # This assumes a constant forcing efficiency (and is estimated based on solenoidal forcing)\n",
    "    U = 0.5 * np.sqrt(ForcingAmpl) \n",
    "    \n",
    "    U_all.append(U)\n",
    "    \n",
    "    # estimate dynamical/turnover time by characteristic length (here, 0.5 which is half the box size) and velocity\n",
    "    T = 0.5 / U\n",
    "    \n",
    "    T_all.append(T)\n",
    "    # convert code time to dynamical times\n",
    "    data[:,0] /= T\n",
    "    \n",
    "    dynTime_all.append(data[:,0])\n",
    "    \n",
    "    Label = r'$B_0$ = %.2f; $\\zeta = %.2f$; $a = %.2f$' % (B0,SolenoidalWeight,ForcingAmpl)\n",
    "    \n",
    "    p[0,0].set_ylabel('Kinetic energy')\n",
    "    p[0,0].plot(data[:,0],data[:,14],label=Label)\n",
    "    p[0,0].set_yscale('log')\n",
    "    p[0,0].set_ylim(1e-4,3e0)\n",
    "    \n",
    "    ke_all.append(data[:,14])\n",
    "    \n",
    "    p[0,1].set_ylabel('Magnetic energy')\n",
    "    p[0,1].plot(data[:,0],data[:,15],label=Label)\n",
    "    p[0,1].set_yscale('log')\n",
    "    p[0,1].set_ylim(5e-5,1e0)\n",
    "    \n",
    "    me_all.append(data[:,15])\n",
    "\n",
    "    p[0,2].set_ylabel('Kinetic/Magnetic energy')\n",
    "    p[0,2].plot(data[:,0],data[:,14]/data[:,15],label=Label)    \n",
    "    p[0,2].set_yscale('log')\n",
    "    p[0,2].set_ylim(1e0,3e2)\n",
    "\n",
    "    p[1,0].set_ylabel('Sonic Mach')\n",
    "    p[1,0].plot(data[:,0],data[:,16],label=Label)   \n",
    "    \n",
    "    sm_all.append(data[:,16])\n",
    "    \n",
    "    p[1,1].set_ylabel('Alfvenic Mach')\n",
    "    p[1,1].plot(data[:,0],data[:,17],label=Label)  \n",
    "    \n",
    "    am_all.append(data[:,17])\n",
    "\n",
    "    p[1,2].set_ylabel('Plasma beta')\n",
    "    p[1,2].plot(data[:,0],data[:,19],label=Label)   \n",
    "    p[1,2].set_yscale('log')\n",
    "    \n",
    "    pb_all.append(data[:,19])\n",
    "    \n",
    "fig.tight_layout()\n",
    "p[0,0].legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create input_parameter array\n",
    "input_param = []\n",
    "for i in range (len(B0_all)):\n",
    "    {\n",
    "        input_param.append([B0_all[i],SolWeight_all[i],ForcingAmp_all[i]])\n",
    "    }\n",
    "\n",
    "#Remove input parameters from simulation that did not run\n",
    "input_param = input_param[0:7]+input_param[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [dynTime_all, ke_all, me_all, sm_all, am_all, pb_all]\n",
    "\n",
    "#Create complete sample data\n",
    "samples = [[],[],[],[],[],[]]\n",
    "\n",
    "#through each data type(time, ke, me, etc)\n",
    "for k in range(len(all_data)):\n",
    "    #through data in each type\n",
    "    for i in range(len(all_data[k])):\n",
    "        sample = []\n",
    "        #create sample linspace(10 pts)\n",
    "        sample_lin = np.linspace(0, len(all_data[k][i])-1, 20)\n",
    "        #print(sample_lin)\n",
    "        for j in sample_lin:\n",
    "            sample.append(all_data[k][i][int(j)])\n",
    "            #print(j)\n",
    "            #print(sample)\n",
    "        samples[k].append(np.array(sample))\n",
    "        #print(samples[k])\n",
    "\n",
    "        \n",
    "#Everything below can (should) be rewritten into a cleaner loop\n",
    "dynTime_samples = samples[0]\n",
    "ke_samples = samples[1]\n",
    "me_samples = samples[2]\n",
    "sm_samples = samples[3]\n",
    "am_samples = samples[4]\n",
    "pb_samples = samples[5]\n",
    "\n",
    "#create training samples\n",
    "tr_dT = dynTime_samples[:][:-1]\n",
    "tr_in = input_param[:][:-1]\n",
    "tr_ke = ke_samples[:][:-1]\n",
    "tr_me = me_samples[:][:-1]\n",
    "tr_sm = sm_samples[:][:-1]\n",
    "tr_am = am_samples[:][:-1]\n",
    "tr_pb = pb_samples[:][:-1]\n",
    "\n",
    "#create test sample\n",
    "te_dT = dynTime_samples[:][-1]\n",
    "te_in = input_param[:][-1]\n",
    "te_ke = ke_samples[:][-1]\n",
    "te_me = me_samples[:][-1]\n",
    "te_sm = sm_samples[:][-1]\n",
    "te_am = am_samples[:][-1]\n",
    "te_pb = pb_samples[:][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kinetic Energy Model\n",
    "\n",
    "kern = RBF()+ConstantKernel()+WhiteKernel()\n",
    "n_res = 10\n",
    "\n",
    "\n",
    "gp_ke = GaussianProcessRegressor(kernel = kern, n_restarts_optimizer = n_res)\n",
    "gp_ke.fit(tr_in, tr_ke)\n",
    "ke_pred, ke_cov = gp_ke.predict(np.array(te_in).reshape(1,-1), return_cov = True)\n",
    "\n",
    "for i in range(len(tr_ke)):\n",
    "\n",
    "        plt.plot(tr_dT[i], tr_ke[i],alpha = 0.2)\n",
    "        \n",
    "plt.scatter(te_dT, te_ke, label = \"Actual\")\n",
    "plt.scatter(te_dT, ke_pred[0], label = \"Predicted\")\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.ylim(1e-4,3e0)\n",
    "plt.legend()\n",
    "#print(ke_pred)\n",
    "\n",
    "#mean and std. dev. of predicted stationary data\n",
    "stat_ke_pred = ke_pred[0][-5:]\n",
    "mean_ke_pred = np.mean(stat_ke_pred)\n",
    "std_ke_pred = np.std(stat_ke_pred)\n",
    "\n",
    "#mean and std. dev. of actual stationary data (testing model)\n",
    "stat_ke_act = te_ke[-5:]\n",
    "mean_ke_act = np.mean(stat_ke_act)\n",
    "std_ke_act = np.std(stat_ke_act)\n",
    "\n",
    "print(\"Predicted Mean: %f, Actual Mean: %f\" %(mean_ke_pred, mean_ke_act))\n",
    "print(\"Predicted Standard Deviation: %f, Actual Standard Deviation: %f\" %(std_ke_pred, std_ke_act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Magnetic Energy Model\n",
    "\n",
    "kern = RBF()+ConstantKernel()+WhiteKernel()\n",
    "n_res = 10\n",
    "\n",
    "\n",
    "gp_me = GaussianProcessRegressor(kernel = kern, n_restarts_optimizer = n_res)\n",
    "gp_me.fit(tr_in, tr_me)\n",
    "me_pred, me_cov = gp_me.predict(np.array(te_in).reshape(1,-1), return_cov = True)\n",
    "\n",
    "for i in range(len(tr_me)):\n",
    "\n",
    "        plt.plot(tr_dT[i], tr_me[i],alpha = 0.2)\n",
    "        \n",
    "plt.scatter(te_dT, te_me, label = \"Actual\")\n",
    "plt.scatter(te_dT, me_pred[0], label = \"Predicted\")\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.ylim(5e-5,1e0)\n",
    "plt.legend()\n",
    "#print(me_pred)\n",
    "\n",
    "#mean and std. dev. of predicted stationary data\n",
    "stat_me_pred = me_pred[0][-5:]\n",
    "mean_me_pred = np.mean(stat_me_pred)\n",
    "std_me_pred = np.std(stat_me_pred)\n",
    "\n",
    "#mean and std. dev. of actual stationary data (testing model)\n",
    "stat_me_act = te_me[-5:]\n",
    "mean_me_act = np.mean(stat_me_act)\n",
    "std_me_act = np.std(stat_me_act)\n",
    "\n",
    "print(\"Predicted Mean: %f, Actual Mean: %f\" %(mean_me_pred, mean_me_act))\n",
    "print(\"Predicted Standard Deviation: %f, Actual Standard Deviation: %f\" %(std_me_pred, std_me_act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sonic Mach Model\n",
    "\n",
    "kern = RBF()+ConstantKernel()+WhiteKernel()\n",
    "n_res = 10\n",
    "\n",
    "\n",
    "gp_sm = GaussianProcessRegressor(kernel = kern, n_restarts_optimizer = n_res)\n",
    "gp_sm.fit(tr_in, tr_sm)\n",
    "sm_pred, sm_cov = gp_sm.predict(np.array(te_in).reshape(1,-1), return_cov = True)\n",
    "\n",
    "for i in range(len(tr_sm)):\n",
    "\n",
    "        plt.plot(tr_dT[i], tr_sm[i],alpha = 0.2)\n",
    "        \n",
    "plt.scatter(te_dT, te_sm, label = \"Actual\")\n",
    "plt.scatter(te_dT, sm_pred[0], label = \"Predicted\")\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "#print(sm_pred)\n",
    "\n",
    "#mean and std. dev. of predicted stationary data\n",
    "stat_sm_pred = sm_pred[0][-5:]\n",
    "mean_sm_pred = np.mean(stat_sm_pred)\n",
    "std_sm_pred = np.std(stat_sm_pred)\n",
    "\n",
    "#mean and std. dev. of actual stationary data (testing model)\n",
    "stat_sm_act = te_sm[-5:]\n",
    "mean_sm_act = np.mean(stat_sm_act)\n",
    "std_sm_act = np.std(stat_sm_act)\n",
    "\n",
    "print(\"Predicted Mean: %f, Actual Mean: %f\" %(mean_sm_pred, mean_sm_act))\n",
    "print(\"Predicted Standard Deviation: %f, Actual Standard Deviation: %f\" %(std_sm_pred, std_sm_act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alfvenic Mach Model\n",
    "\n",
    "kern = RBF()+ConstantKernel()+WhiteKernel()\n",
    "n_res = 10\n",
    "\n",
    "\n",
    "gp_am = GaussianProcessRegressor(kernel = kern, n_restarts_optimizer = n_res)\n",
    "gp_am.fit(tr_in, tr_am)\n",
    "am_pred, am_cov = gp_am.predict(np.array(te_in).reshape(1,-1), return_cov = True)\n",
    "\n",
    "for i in range(len(tr_am)):\n",
    "\n",
    "        plt.plot(tr_dT[i], tr_am[i],alpha = 0.2)\n",
    "        \n",
    "plt.scatter(te_dT, te_am, label = \"Actual\")\n",
    "plt.scatter(te_dT, am_pred[0], label = \"Predicted\")\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "#print(am_pred)\n",
    "\n",
    "#mean and std. dev. of predicted stationary data\n",
    "stat_am_pred = am_pred[0][-5:]\n",
    "mean_am_pred = np.mean(stat_am_pred)\n",
    "std_am_pred = np.std(stat_am_pred)\n",
    "\n",
    "#mean and std. dev. of actual stationary data (testing model)\n",
    "stat_am_act = te_am[-5:]\n",
    "mean_am_act = np.mean(stat_am_act)\n",
    "std_am_act = np.std(stat_am_act)\n",
    "\n",
    "print(\"Predicted Mean: %f, Actual Mean: %f\" %(mean_am_pred, mean_am_act))\n",
    "print(\"Predicted Standard Deviation: %f, Actual Standard Deviation: %f\" %(std_am_pred, std_am_act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plasma Beta Model\n",
    "\n",
    "kern = RBF()+ConstantKernel()+WhiteKernel()\n",
    "n_res = 10\n",
    "\n",
    "\n",
    "gp_pb = GaussianProcessRegressor(kernel = kern, n_restarts_optimizer = n_res)\n",
    "gp_pb.fit(tr_in, tr_pb)\n",
    "pb_pred, pb_cov = gp_pb.predict(np.array(te_in).reshape(1,-1), return_cov = True)\n",
    "\n",
    "for i in range(len(tr_pb)):\n",
    "\n",
    "        plt.plot(tr_dT[i], tr_pb[i],alpha = 0.2)\n",
    "        \n",
    "plt.scatter(te_dT, te_pb, label = \"Actual\")\n",
    "plt.scatter(te_dT, pb_pred[0], label = \"Predicted\")\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "#print(pb_pred)\n",
    "\n",
    "#mean and std. dev. of predicted stationary data\n",
    "stat_pb_pred = pb_pred[0][-5:]\n",
    "mean_pb_pred = np.mean(stat_pb_pred)\n",
    "std_pb_pred = np.std(stat_pb_pred)\n",
    "\n",
    "#mean and std. dev. of actual stationary data (testing model)\n",
    "stat_pb_act = te_pb[-5:]\n",
    "mean_pb_act = np.mean(stat_pb_act)\n",
    "std_pb_act = np.std(stat_pb_act)\n",
    "\n",
    "print(\"Predicted Mean: %f, Actual Mean: %f\" %(mean_pb_pred, mean_pb_act))\n",
    "print(\"Predicted Standard Deviation: %f, Actual Standard Deviation: %f\" %(std_pb_pred, std_pb_act))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
